{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf441699",
   "metadata": {},
   "source": [
    "Zentrale Messgrössen übersicht"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe6ed71",
   "metadata": {},
   "source": [
    "o\tRuntime: Durchschnitts- oder Gesamtlaufzeiten für verschiedene Datensätze und Parameter.\n",
    "\n",
    "o\tLog-Likelihood: Endwerte und ggf. Konvergenzverhalten.\n",
    "\n",
    "o\tFehlgeschlagene Runs: Falls relevant (z. B. „2 out of 30 runs did not converge“)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d38cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337759ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Sequence_Number</th>\n",
       "      <th>Alignment_Length</th>\n",
       "      <th>Model</th>\n",
       "      <th>GAPS</th>\n",
       "      <th>Max_iters</th>\n",
       "      <th>Runtime (s)</th>\n",
       "      <th>Final_Log-likelihood</th>\n",
       "      <th>RF_distance</th>\n",
       "      <th>Normalized_RF_distance</th>\n",
       "      <th>Output_Complete</th>\n",
       "      <th>Files_Complete</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dna</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.001</td>\n",
       "      <td>jarvd5a_intron_1521.processed.fasta</td>\n",
       "      <td>46</td>\n",
       "      <td>16250</td>\n",
       "      <td>GTR</td>\n",
       "      <td>pip</td>\n",
       "      <td>5</td>\n",
       "      <td>2322.0</td>\n",
       "      <td>-401257.92930</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.6591</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dna</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.001</td>\n",
       "      <td>jarvd5b_bin.1136.processed.fasta</td>\n",
       "      <td>48</td>\n",
       "      <td>14401</td>\n",
       "      <td>GTR</td>\n",
       "      <td>pip</td>\n",
       "      <td>5</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>-339872.92810</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.8043</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dna</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.001</td>\n",
       "      <td>misod2a_EOG5CVDNS.processed.fasta</td>\n",
       "      <td>134</td>\n",
       "      <td>3261</td>\n",
       "      <td>GTR</td>\n",
       "      <td>pip</td>\n",
       "      <td>5</td>\n",
       "      <td>9815.0</td>\n",
       "      <td>-331430.79060</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.6288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dna</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.001</td>\n",
       "      <td>misod2b_EOG5CVDNS.processed.fasta</td>\n",
       "      <td>134</td>\n",
       "      <td>2174</td>\n",
       "      <td>GTR</td>\n",
       "      <td>pip</td>\n",
       "      <td>5</td>\n",
       "      <td>5082.0</td>\n",
       "      <td>-149770.57150</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dna</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.001</td>\n",
       "      <td>prumd6_L37.processed.fasta</td>\n",
       "      <td>200</td>\n",
       "      <td>1645</td>\n",
       "      <td>GTR</td>\n",
       "      <td>pip</td>\n",
       "      <td>5</td>\n",
       "      <td>6309.0</td>\n",
       "      <td>-75654.06647</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type Difficulty  Epsilon                              Dataset  \\\n",
       "0  dna       easy    0.001  jarvd5a_intron_1521.processed.fasta   \n",
       "1  dna       easy    0.001     jarvd5b_bin.1136.processed.fasta   \n",
       "2  dna       easy    0.001    misod2a_EOG5CVDNS.processed.fasta   \n",
       "3  dna       easy    0.001    misod2b_EOG5CVDNS.processed.fasta   \n",
       "4  dna       easy    0.001           prumd6_L37.processed.fasta   \n",
       "\n",
       "   Sequence_Number  Alignment_Length Model GAPS  Max_iters  Runtime (s)  \\\n",
       "0               46             16250   GTR  pip          5       2322.0   \n",
       "1               48             14401   GTR  pip          5       1672.0   \n",
       "2              134              3261   GTR  pip          5       9815.0   \n",
       "3              134              2174   GTR  pip          5       5082.0   \n",
       "4              200              1645   GTR  pip          5       6309.0   \n",
       "\n",
       "   Final_Log-likelihood  RF_distance  Normalized_RF_distance  Output_Complete  \\\n",
       "0         -401257.92930         58.0                  0.6591                1   \n",
       "1         -339872.92810         74.0                  0.8043                1   \n",
       "2         -331430.79060        166.0                  0.6288                1   \n",
       "3         -149770.57150        170.0                  0.6439                1   \n",
       "4          -75654.06647         96.0                  0.2424                1   \n",
       "\n",
       "   Files_Complete Comment  \n",
       "0               1     NaN  \n",
       "1               1     NaN  \n",
       "2               1     NaN  \n",
       "3               1     NaN  \n",
       "4               1     NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Daten laden (Dateiname ist Data_Fused.csv mit Semikolon als Trennzeichen)\n",
    "df = pd.read_csv('Data_Fused.csv', delimiter=';')\n",
    "\n",
    "df.head()  # Erste Zeilen des DataFrames anzeigen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c2d3b",
   "metadata": {},
   "source": [
    "Mean runtime per Difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6d74b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittsgeschwindigkeit für dna_easy: 2438.93 s\n",
      "\n",
      "Durchschnittsgeschwindigkeit je Epsilon:\n",
      "  Epsilon=0.000100 → 2468.00 s\n",
      "  Epsilon=0.000500 → 2837.20 s\n",
      "  Epsilon=0.001000 → 2597.60 s\n",
      "  Epsilon=0.005000 → 2423.70 s\n",
      "  Epsilon=0.010000 → 2543.00 s\n",
      "  Epsilon=0.100000 → 2276.80 s\n",
      "  Epsilon=0.500000 → 1926.20 s\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittsgeschwindigkeit dna_easy\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt\n",
    "avg_speed_dna_easy = filtered['Runtime (s)'].mean()\n",
    "print(f\"Durchschnittsgeschwindigkeit für dna_easy: {avg_speed_dna_easy:.2f} s\\n\")\n",
    "\n",
    "# 3. Spezifische Epsilon-Werte\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Nur die gewünschten Epsilons herausfiltern\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnitt pro Epsilon berechnen\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittsgeschwindigkeit je Epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c87fd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittsgeschwindigkeit für dna_easy: 1435.39 s\n",
      "\n",
      "Durchschnittsgeschwindigkeit je Epsilon:\n",
      "  Epsilon=0.000100 → 1619.60 s\n",
      "  Epsilon=0.000500 → 1580.00 s\n",
      "  Epsilon=0.001000 → 1536.30 s\n",
      "  Epsilon=0.005000 → 1610.70 s\n",
      "  Epsilon=0.010000 → 1402.10 s\n",
      "  Epsilon=0.100000 → 1156.50 s\n",
      "  Epsilon=0.500000 → 1142.50 s\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittsgeschwindigkeit dna_medium\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt\n",
    "avg_speed_dna_easy = filtered['Runtime (s)'].mean()\n",
    "print(f\"Durchschnittsgeschwindigkeit für dna_easy: {avg_speed_dna_easy:.2f} s\\n\")\n",
    "\n",
    "# 3. Spezifische Epsilon-Werte\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Nur die gewünschten Epsilons herausfiltern\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnitt pro Epsilon berechnen\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittsgeschwindigkeit je Epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51af5263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittsgeschwindigkeit für dna_easy: 476.66 s\n",
      "\n",
      "Durchschnittsgeschwindigkeit je Epsilon:\n",
      "  Epsilon=0.000100 → 632.10 s\n",
      "  Epsilon=0.000500 → 523.60 s\n",
      "  Epsilon=0.001000 → 532.60 s\n",
      "  Epsilon=0.005000 → 506.00 s\n",
      "  Epsilon=0.010000 → 460.00 s\n",
      "  Epsilon=0.100000 → 366.50 s\n",
      "  Epsilon=0.500000 → 315.80 s\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittsgeschwindigkeit dna_hard\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt\n",
    "avg_speed_dna_easy = filtered['Runtime (s)'].mean()\n",
    "print(f\"Durchschnittsgeschwindigkeit für dna_easy: {avg_speed_dna_easy:.2f} s\\n\")\n",
    "\n",
    "# 3. Spezifische Epsilon-Werte\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Nur die gewünschten Epsilons herausfiltern\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnitt pro Epsilon berechnen\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittsgeschwindigkeit je Epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62330096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittsgeschwindigkeit für dna_easy: 378.05 s\n",
      "\n",
      "Durchschnittsgeschwindigkeit je Epsilon:\n",
      "  Epsilon=0.000100 → 425.20 s\n",
      "  Epsilon=0.000500 → 365.91 s\n",
      "  Epsilon=0.001000 → 384.73 s\n",
      "  Epsilon=0.005000 → 415.45 s\n",
      "  Epsilon=0.010000 → 381.82 s\n",
      "  Epsilon=0.100000 → 365.18 s\n",
      "  Epsilon=0.500000 → 312.36 s\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittsgeschwindigkeit aa_easy\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt\n",
    "avg_speed_dna_easy = filtered['Runtime (s)'].mean()\n",
    "print(f\"Durchschnittsgeschwindigkeit für dna_easy: {avg_speed_dna_easy:.2f} s\\n\")\n",
    "\n",
    "# 3. Spezifische Epsilon-Werte\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Nur die gewünschten Epsilons herausfiltern\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnitt pro Epsilon berechnen\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittsgeschwindigkeit je Epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4905ff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittsgeschwindigkeit für dna_easy: 415.52 s\n",
      "\n",
      "Durchschnittsgeschwindigkeit je Epsilon:\n",
      "  Epsilon=0.000100 → 495.11 s\n",
      "  Epsilon=0.000500 → 463.22 s\n",
      "  Epsilon=0.001000 → 440.00 s\n",
      "  Epsilon=0.005000 → 442.67 s\n",
      "  Epsilon=0.010000 → 399.89 s\n",
      "  Epsilon=0.100000 → 348.44 s\n",
      "  Epsilon=0.500000 → 319.33 s\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittsgeschwindigkeit aa_medium\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt\n",
    "avg_speed_dna_easy = filtered['Runtime (s)'].mean()\n",
    "print(f\"Durchschnittsgeschwindigkeit für dna_easy: {avg_speed_dna_easy:.2f} s\\n\")\n",
    "\n",
    "# 3. Spezifische Epsilon-Werte\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Nur die gewünschten Epsilons herausfiltern\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnitt pro Epsilon berechnen\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittsgeschwindigkeit je Epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40c852d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittsgeschwindigkeit für dna_easy: 212.10 s\n",
      "\n",
      "Durchschnittsgeschwindigkeit je Epsilon:\n",
      "  Epsilon=0.000100 → 280.44 s\n",
      "  Epsilon=0.000500 → 258.11 s\n",
      "  Epsilon=0.001000 → 214.56 s\n",
      "  Epsilon=0.005000 → 203.56 s\n",
      "  Epsilon=0.010000 → 191.44 s\n",
      "  Epsilon=0.100000 → 183.33 s\n",
      "  Epsilon=0.500000 → 153.22 s\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittsgeschwindigkeit aa_hard\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt\n",
    "avg_speed_dna_easy = filtered['Runtime (s)'].mean()\n",
    "print(f\"Durchschnittsgeschwindigkeit für dna_easy: {avg_speed_dna_easy:.2f} s\\n\")\n",
    "\n",
    "# 3. Spezifische Epsilon-Werte\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Nur die gewünschten Epsilons herausfiltern\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnitt pro Epsilon berechnen\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittsgeschwindigkeit je Epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d007da3a",
   "metadata": {},
   "source": [
    "Mean Log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2144039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche Final-Loglikelihood für dna_easy: -156811.3702\n",
      "\n",
      "Durchschnittliche Final-Loglikelihood je Epsilon:\n",
      "  Epsilon=0.000100 → -156778.1694\n",
      "  Epsilon=0.000500 → -156846.4204\n",
      "  Epsilon=0.001000 → -156762.0451\n",
      "  Epsilon=0.005000 → -156757.3232\n",
      "  Epsilon=0.010000 → -156839.9302\n",
      "  Epsilon=0.100000 → -156833.9995\n",
      "  Epsilon=0.500000 → -156861.7040\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittliche Final-Loglikelihood dna_easy\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt der Final_Log-likelihood\n",
    "avg_loglik_dna_easy = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Durchschnittliche Final-Loglikelihood für dna_easy: {avg_loglik_dna_easy:.4f}\\n\")\n",
    "\n",
    "# 3. Epsilon-Werte definieren\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Gefilterte Daten nur für diese Epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnittliche Final_Log-likelihood pro Epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittliche Final-Loglikelihood je Epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df9ff442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche Final-Loglikelihood für dna_easy: -63492.8550\n",
      "\n",
      "Durchschnittliche Final-Loglikelihood je Epsilon:\n",
      "  Epsilon=0.000100 → -63482.5385\n",
      "  Epsilon=0.000500 → -63477.9327\n",
      "  Epsilon=0.001000 → -63474.9843\n",
      "  Epsilon=0.005000 → -63509.3536\n",
      "  Epsilon=0.010000 → -63461.2627\n",
      "  Epsilon=0.100000 → -63522.0247\n",
      "  Epsilon=0.500000 → -63521.8880\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittliche Final-Loglikelihood dna_medium\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt der Final_Log-likelihood\n",
    "avg_loglik_dna_easy = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Durchschnittliche Final-Loglikelihood für dna_easy: {avg_loglik_dna_easy:.4f}\\n\")\n",
    "\n",
    "# 3. Epsilon-Werte definieren\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Gefilterte Daten nur für diese Epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnittliche Final_Log-likelihood pro Epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittliche Final-Loglikelihood je Epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "955e8523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche Final-Loglikelihood für dna_easy: -14942.8450\n",
      "\n",
      "Durchschnittliche Final-Loglikelihood je Epsilon:\n",
      "  Epsilon=0.000100 → -14932.8311\n",
      "  Epsilon=0.000500 → -14942.4876\n",
      "  Epsilon=0.001000 → -14954.1691\n",
      "  Epsilon=0.005000 → -14933.4424\n",
      "  Epsilon=0.010000 → -14934.2122\n",
      "  Epsilon=0.100000 → -14967.3503\n",
      "  Epsilon=0.500000 → -14935.4220\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittliche Final-Loglikelihood dna_hard\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt der Final_Log-likelihood\n",
    "avg_loglik_dna_easy = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Durchschnittliche Final-Loglikelihood für dna_easy: {avg_loglik_dna_easy:.4f}\\n\")\n",
    "\n",
    "# 3. Epsilon-Werte definieren\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Gefilterte Daten nur für diese Epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnittliche Final_Log-likelihood pro Epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittliche Final-Loglikelihood je Epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb27f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche Final-Loglikelihood für dna_easy: -21462.8462\n",
      "\n",
      "Durchschnittliche Final-Loglikelihood je Epsilon:\n",
      "  Epsilon=0.000100 → -21460.8044\n",
      "  Epsilon=0.000500 → -21464.7818\n",
      "  Epsilon=0.001000 → -21457.9213\n",
      "  Epsilon=0.005000 → -21465.9598\n",
      "  Epsilon=0.010000 → -21459.0454\n",
      "  Epsilon=0.100000 → -21456.1469\n",
      "  Epsilon=0.500000 → -21475.2639\n"
     ]
    }
   ],
   "source": [
    "#Durchschnittliche Final-Loglikelihood aa_easy\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt der Final_Log-likelihood\n",
    "avg_loglik_dna_easy = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Durchschnittliche Final-Loglikelihood für dna_easy: {avg_loglik_dna_easy:.4f}\\n\")\n",
    "\n",
    "# 3. Epsilon-Werte definieren\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Gefilterte Daten nur für diese Epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnittliche Final_Log-likelihood pro Epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittliche Final-Loglikelihood je Epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9926e5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche Final-Loglikelihood für dna_easy: -17796.0500\n",
      "\n",
      "Durchschnittliche Final-Loglikelihood je Epsilon:\n",
      "  Epsilon=0.000100 → -17792.7813\n",
      "  Epsilon=0.000500 → -17794.3679\n",
      "  Epsilon=0.001000 → -17793.9185\n",
      "  Epsilon=0.005000 → -17793.2383\n",
      "  Epsilon=0.010000 → -17800.5230\n",
      "  Epsilon=0.100000 → -17792.4883\n",
      "  Epsilon=0.500000 → -17805.0325\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittliche Final-Loglikelihood aa_medium\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt der Final_Log-likelihood\n",
    "avg_loglik_dna_easy = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Durchschnittliche Final-Loglikelihood für dna_easy: {avg_loglik_dna_easy:.4f}\\n\")\n",
    "\n",
    "# 3. Epsilon-Werte definieren\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Gefilterte Daten nur für diese Epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnittliche Final_Log-likelihood pro Epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittliche Final-Loglikelihood je Epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64c00187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche Final-Loglikelihood für dna_easy: -5949.1022\n",
      "\n",
      "Durchschnittliche Final-Loglikelihood je Epsilon:\n",
      "  Epsilon=0.000100 → -5950.2694\n",
      "  Epsilon=0.000500 → -5951.0615\n",
      "  Epsilon=0.001000 → -5946.4386\n",
      "  Epsilon=0.005000 → -5943.9783\n",
      "  Epsilon=0.010000 → -5950.1080\n",
      "  Epsilon=0.100000 → -5951.7140\n",
      "  Epsilon=0.500000 → -5950.1457\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittliche Final-Loglikelihood aa_hard\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt der Final_Log-likelihood\n",
    "avg_loglik_dna_easy = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Durchschnittliche Final-Loglikelihood für dna_easy: {avg_loglik_dna_easy:.4f}\\n\")\n",
    "\n",
    "# 3. Epsilon-Werte definieren\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Gefilterte Daten nur für diese Epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnittliche Final_Log-likelihood pro Epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittliche Final-Loglikelihood je Epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d2a79",
   "metadata": {},
   "source": [
    "Anzahl der Fehlerhaften runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7d8fd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 von 70 Runs waren unvollständig.\n",
      "\n",
      "Unvollständige Runs (Dataset + Kommentar):\n",
      "                                 Dataset                    Comment\n",
      "63            prumd6_L37.processed.fasta       Unfinished .log file\n",
      "118  jarvd5a_intron_1521.processed.fasta  No .logl and _tree.newick\n",
      "119     jarvd5b_bin.1136.processed.fasta  No .logl and _tree.newick\n",
      "120    misod2a_EOG5CVDNS.processed.fasta  No .logl and _tree.newick\n",
      "121    misod2b_EOG5CVDNS.processed.fasta  No .logl and _tree.newick\n",
      "122           prumd6_L37.processed.fasta  No .logl and _tree.newick\n"
     ]
    }
   ],
   "source": [
    "# Fehlerhafte Runs dna_easy (über 'comment' erkannt)\n",
    "\n",
    "# 1. Hauptfilter (wie bisher)\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Anzahl aller Runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Unvollständige Runs = solche mit Kommentar (nicht leer / nicht NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Anzahl der unvollständigen Runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Ausgabe\n",
    "print(f\"{failed_runs} von {total_runs} Runs waren unvollständig.\\n\")\n",
    "\n",
    "# 6. Ausgabe der unvollständigen Runs mit Dataset und Comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Unvollständige Runs (Dataset + Kommentar):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Spalten 'Dataset' oder 'comment' nicht gefunden – hier sind alle verfügbaren Spalten:\")\n",
    "    print(incomplete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eebae50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 von 70 Runs waren unvollständig.\n",
      "\n",
      "Unvollständige Runs (Dataset + Kommentar):\n",
      "Empty DataFrame\n",
      "Columns: [Dataset, Comment]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Fehlerhafte Runs dna_medium (über 'comment' erkannt)\n",
    "\n",
    "# 1. Hauptfilter (wie bisher)\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Anzahl aller Runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Unvollständige Runs = solche mit Kommentar (nicht leer / nicht NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Anzahl der unvollständigen Runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Ausgabe\n",
    "print(f\"{failed_runs} von {total_runs} Runs waren unvollständig.\\n\")\n",
    "\n",
    "# 6. Ausgabe der unvollständigen Runs mit Dataset und Comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Unvollständige Runs (Dataset + Kommentar):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Spalten 'Dataset' oder 'comment' nicht gefunden – hier sind alle verfügbaren Spalten:\")\n",
    "    print(incomplete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a99b042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 von 70 Runs waren unvollständig.\n",
      "\n",
      "Unvollständige Runs (Dataset + Kommentar):\n",
      "Empty DataFrame\n",
      "Columns: [Dataset, Comment]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Fehlerhafte Runs dna_hard (über 'comment' erkannt)\n",
    "\n",
    "# 1. Hauptfilter (wie bisher)\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Anzahl aller Runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Unvollständige Runs = solche mit Kommentar (nicht leer / nicht NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Anzahl der unvollständigen Runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Ausgabe\n",
    "print(f\"{failed_runs} von {total_runs} Runs waren unvollständig.\\n\")\n",
    "\n",
    "# 6. Ausgabe der unvollständigen Runs mit Dataset und Comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Unvollständige Runs (Dataset + Kommentar):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Spalten 'Dataset' oder 'comment' nicht gefunden – hier sind alle verfügbaren Spalten:\")\n",
    "    print(incomplete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "900772f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 von 77 Runs waren unvollständig.\n",
      "\n",
      "Unvollständige Runs (Dataset + Kommentar):\n",
      "                                    Dataset      Comment\n",
      "31   chena4_Pro_ENSG00000143061.refined.fas  Not started\n",
      "90   chena4_Pro_ENSG00000143061.refined.fas  Not Started\n",
      "149  chena4_Pro_ENSG00000143061.refined.fas  Not Started\n",
      "208  chena4_Pro_ENSG00000143061.refined.fas  Not Started\n",
      "267  chena4_Pro_ENSG00000143061.refined.fas  Not Started\n",
      "326  chena4_Pro_ENSG00000143061.refined.fas  Not Started\n",
      "385  chena4_Pro_ENSG00000143061.refined.fas  Not Started\n"
     ]
    }
   ],
   "source": [
    "# Fehlerhafte Runs aa_easy (über 'comment' erkannt)\n",
    "\n",
    "# 1. Hauptfilter (wie bisher)\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Anzahl aller Runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Unvollständige Runs = solche mit Kommentar (nicht leer / nicht NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Anzahl der unvollständigen Runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Ausgabe\n",
    "print(f\"{failed_runs} von {total_runs} Runs waren unvollständig.\\n\")\n",
    "\n",
    "# 6. Ausgabe der unvollständigen Runs mit Dataset und Comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Unvollständige Runs (Dataset + Kommentar):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Spalten 'Dataset' oder 'comment' nicht gefunden – hier sind alle verfügbaren Spalten:\")\n",
    "    print(incomplete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca792f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 von 63 Runs waren unvollständig.\n",
      "\n",
      "Unvollständige Runs (Dataset + Kommentar):\n",
      "                                    Dataset      Comment\n",
      "42   chena4_Pro_ENSG00000156958.refined.fas  Not Started\n",
      "101  chena4_Pro_ENSG00000156958.refined.fas  Not Started\n",
      "160  chena4_Pro_ENSG00000156958.refined.fas  Not Started\n",
      "219  chena4_Pro_ENSG00000156958.refined.fas  Not Started\n",
      "337  chena4_Pro_ENSG00000156958.refined.fas  Not Started\n",
      "396  chena4_Pro_ENSG00000156958.refined.fas  Not Started\n"
     ]
    }
   ],
   "source": [
    "# Fehlerhafte Runs aa_medium (über 'comment' erkannt)\n",
    "\n",
    "# 1. Hauptfilter (wie bisher)\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Anzahl aller Runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Unvollständige Runs = solche mit Kommentar (nicht leer / nicht NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Anzahl der unvollständigen Runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Ausgabe\n",
    "print(f\"{failed_runs} von {total_runs} Runs waren unvollständig.\\n\")\n",
    "\n",
    "# 6. Ausgabe der unvollständigen Runs mit Dataset und Comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Unvollständige Runs (Dataset + Kommentar):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Spalten 'Dataset' oder 'comment' nicht gefunden – hier sind alle verfügbaren Spalten:\")\n",
    "    print(incomplete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49629416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 von 63 Runs waren unvollständig.\n",
      "\n",
      "Unvollständige Runs (Dataset + Kommentar):\n",
      "                                    Dataset     Comment\n",
      "51   chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "110  chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "169  chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "228  chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "287  chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "346  chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "405  chena4_Pro_ENSG00000141543.refined.fas  No Started\n"
     ]
    }
   ],
   "source": [
    "# Fehlerhafte Runs aa_hard (über 'comment' erkannt)\n",
    "\n",
    "# 1. Hauptfilter (wie bisher)\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Anzahl aller Runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Unvollständige Runs = solche mit Kommentar (nicht leer / nicht NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Anzahl der unvollständigen Runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Ausgabe\n",
    "print(f\"{failed_runs} von {total_runs} Runs waren unvollständig.\\n\")\n",
    "\n",
    "# 6. Ausgabe der unvollständigen Runs mit Dataset und Comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Unvollständige Runs (Dataset + Kommentar):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Spalten 'Dataset' oder 'comment' nicht gefunden – hier sind alle verfügbaren Spalten:\")\n",
    "    print(incomplete)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
