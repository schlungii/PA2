{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf441699",
   "metadata": {},
   "source": [
    "### Overview of Key Measurement Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe6ed71",
   "metadata": {},
   "source": [
    "This notebook performs a systematic analysis of algorithm performance across different datasets, difficulty levels, and parameter settings. For each combination of type (DNA/AA) and difficulty (easy/medium/hard), the following key measurement variables are evaluated:\n",
    "\n",
    "- Runtime: Average and per-parameter runtimes across datasets, allowing comparison of computational efficiency.\n",
    "\n",
    "- Log-likelihood: Final log-likelihood values, including potential indicators of convergence behaviour.\n",
    "\n",
    "- Failed runs: Detection of incomplete or invalid runs based on comment fields (e.g., “2 out of 30 runs did not converge”).\n",
    "\n",
    "These metrics collectively provide insight into both the quality and stability of the algorithm’s performance under varying conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e71e0ce",
   "metadata": {},
   "source": [
    "Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d38cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e48bc6",
   "metadata": {},
   "source": [
    "Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337759ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Epsilon</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Sequence_Number</th>\n",
       "      <th>Alignment_Length</th>\n",
       "      <th>Model</th>\n",
       "      <th>GAPS</th>\n",
       "      <th>Max_iters</th>\n",
       "      <th>Runtime (s)</th>\n",
       "      <th>Final_Log-likelihood</th>\n",
       "      <th>RF_distance</th>\n",
       "      <th>Normalized_RF_distance</th>\n",
       "      <th>Output_Complete</th>\n",
       "      <th>Files_Complete</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dna</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.001</td>\n",
       "      <td>jarvd5a_intron_1521.processed.fasta</td>\n",
       "      <td>46</td>\n",
       "      <td>16250</td>\n",
       "      <td>GTR</td>\n",
       "      <td>pip</td>\n",
       "      <td>5</td>\n",
       "      <td>2322.0</td>\n",
       "      <td>-401257.92930</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.6591</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dna</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.001</td>\n",
       "      <td>jarvd5b_bin.1136.processed.fasta</td>\n",
       "      <td>48</td>\n",
       "      <td>14401</td>\n",
       "      <td>GTR</td>\n",
       "      <td>pip</td>\n",
       "      <td>5</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>-339872.92810</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.8043</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dna</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.001</td>\n",
       "      <td>misod2a_EOG5CVDNS.processed.fasta</td>\n",
       "      <td>134</td>\n",
       "      <td>3261</td>\n",
       "      <td>GTR</td>\n",
       "      <td>pip</td>\n",
       "      <td>5</td>\n",
       "      <td>9815.0</td>\n",
       "      <td>-331430.79060</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.6288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dna</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.001</td>\n",
       "      <td>misod2b_EOG5CVDNS.processed.fasta</td>\n",
       "      <td>134</td>\n",
       "      <td>2174</td>\n",
       "      <td>GTR</td>\n",
       "      <td>pip</td>\n",
       "      <td>5</td>\n",
       "      <td>5082.0</td>\n",
       "      <td>-149770.57150</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dna</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.001</td>\n",
       "      <td>prumd6_L37.processed.fasta</td>\n",
       "      <td>200</td>\n",
       "      <td>1645</td>\n",
       "      <td>GTR</td>\n",
       "      <td>pip</td>\n",
       "      <td>5</td>\n",
       "      <td>6309.0</td>\n",
       "      <td>-75654.06647</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type Difficulty  Epsilon                              Dataset  \\\n",
       "0  dna       easy    0.001  jarvd5a_intron_1521.processed.fasta   \n",
       "1  dna       easy    0.001     jarvd5b_bin.1136.processed.fasta   \n",
       "2  dna       easy    0.001    misod2a_EOG5CVDNS.processed.fasta   \n",
       "3  dna       easy    0.001    misod2b_EOG5CVDNS.processed.fasta   \n",
       "4  dna       easy    0.001           prumd6_L37.processed.fasta   \n",
       "\n",
       "   Sequence_Number  Alignment_Length Model GAPS  Max_iters  Runtime (s)  \\\n",
       "0               46             16250   GTR  pip          5       2322.0   \n",
       "1               48             14401   GTR  pip          5       1672.0   \n",
       "2              134              3261   GTR  pip          5       9815.0   \n",
       "3              134              2174   GTR  pip          5       5082.0   \n",
       "4              200              1645   GTR  pip          5       6309.0   \n",
       "\n",
       "   Final_Log-likelihood  RF_distance  Normalized_RF_distance  Output_Complete  \\\n",
       "0         -401257.92930         58.0                  0.6591                1   \n",
       "1         -339872.92810         74.0                  0.8043                1   \n",
       "2         -331430.79060        166.0                  0.6288                1   \n",
       "3         -149770.57150        170.0                  0.6439                1   \n",
       "4          -75654.06647         96.0                  0.2424                1   \n",
       "\n",
       "   Files_Complete Comment  \n",
       "0               1     NaN  \n",
       "1               1     NaN  \n",
       "2               1     NaN  \n",
       "3               1     NaN  \n",
       "4               1     NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data (filename is Data_Fused.csv with semicolon as separator)\n",
    "df = pd.read_csv('Data_Fused.csv', delimiter=';')\n",
    "\n",
    "df.head()  # Display the first rows of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c2d3b",
   "metadata": {},
   "source": [
    "Mean runtime per Difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6d74b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime for dna_easy: 2438.93 s\n",
      "\n",
      "Average runtime per epsilon:\n",
      "  Epsilon=0.000100 → 2468.00 s\n",
      "  Epsilon=0.000500 → 2837.20 s\n",
      "  Epsilon=0.001000 → 2597.60 s\n",
      "  Epsilon=0.005000 → 2423.70 s\n",
      "  Epsilon=0.010000 → 2543.00 s\n",
      "  Epsilon=0.100000 → 2276.80 s\n",
      "  Epsilon=0.500000 → 1926.20 s\n"
     ]
    }
   ],
   "source": [
    "# Average speed dna_easy\n",
    "\n",
    "# 1. Main filter\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Overall average\n",
    "avg_speed_dna_easy = filtered['Runtime (s)'].mean()\n",
    "print(f\"Average runtime for dna_easy: {avg_speed_dna_easy:.2f} s\\n\")\n",
    "\n",
    "# 3. Specific epsilon values\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Filter only the desired epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Calculate average per epsilon\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Output\n",
    "print(\"Average runtime per epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c87fd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime for dna_easy: 1435.39 s\n",
      "\n",
      "Average runtime per epsilon:\n",
      "  Epsilon=0.000100 → 1619.60 s\n",
      "  Epsilon=0.000500 → 1580.00 s\n",
      "  Epsilon=0.001000 → 1536.30 s\n",
      "  Epsilon=0.005000 → 1610.70 s\n",
      "  Epsilon=0.010000 → 1402.10 s\n",
      "  Epsilon=0.100000 → 1156.50 s\n",
      "  Epsilon=0.500000 → 1142.50 s\n"
     ]
    }
   ],
   "source": [
    "# Average speed dna_medium\n",
    "\n",
    "# 1. Main filter\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Overall average\n",
    "avg_speed_dna_medium = filtered['Runtime (s)'].mean()\n",
    "print(f\"Average runtime for dna_easy: {avg_speed_dna_medium:.2f} s\\n\")\n",
    "\n",
    "# 3. Specific epsilon values\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Filter only the desired epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Compute average per epsilon\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Output\n",
    "print(\"Average runtime per epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51af5263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime for dna_easy: 476.66 s\n",
      "\n",
      "Average runtime per epsilon:\n",
      "  Epsilon=0.000100 → 632.10 s\n",
      "  Epsilon=0.000500 → 523.60 s\n",
      "  Epsilon=0.001000 → 532.60 s\n",
      "  Epsilon=0.005000 → 506.00 s\n",
      "  Epsilon=0.010000 → 460.00 s\n",
      "  Epsilon=0.100000 → 366.50 s\n",
      "  Epsilon=0.500000 → 315.80 s\n"
     ]
    }
   ],
   "source": [
    "# Average speed dna_hard\n",
    "\n",
    "# 1. Main filter\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Overall average\n",
    "avg_speed_dna_hard = filtered['Runtime (s)'].mean()\n",
    "print(f\"Average runtime for dna_easy: {avg_speed_dna_hard:.2f} s\\n\")\n",
    "\n",
    "# 3. Specific epsilon values\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Filter only the desired epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Compute average per epsilon\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Output\n",
    "print(\"Average runtime per epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62330096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime for dna_easy: 378.05 s\n",
      "\n",
      "Average runtime per epsilon:\n",
      "  Epsilon=0.000100 → 425.20 s\n",
      "  Epsilon=0.000500 → 365.91 s\n",
      "  Epsilon=0.001000 → 384.73 s\n",
      "  Epsilon=0.005000 → 415.45 s\n",
      "  Epsilon=0.010000 → 381.82 s\n",
      "  Epsilon=0.100000 → 365.18 s\n",
      "  Epsilon=0.500000 → 312.36 s\n"
     ]
    }
   ],
   "source": [
    "# Average speed aa_easy\n",
    "\n",
    "# 1. Main filter\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Overall average\n",
    "avg_speed_aa_easy = filtered['Runtime (s)'].mean()\n",
    "print(f\"Average runtime for dna_easy: {avg_speed_aa_easy:.2f} s\\n\")\n",
    "\n",
    "# 3. Specific epsilon values\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Filter only the desired epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Compute average per epsilon\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Output\n",
    "print(\"Average runtime per epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4905ff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime for dna_easy: 415.52 s\n",
      "\n",
      "Average runtime per epsilon:\n",
      "  Epsilon=0.000100 → 495.11 s\n",
      "  Epsilon=0.000500 → 463.22 s\n",
      "  Epsilon=0.001000 → 440.00 s\n",
      "  Epsilon=0.005000 → 442.67 s\n",
      "  Epsilon=0.010000 → 399.89 s\n",
      "  Epsilon=0.100000 → 348.44 s\n",
      "  Epsilon=0.500000 → 319.33 s\n"
     ]
    }
   ],
   "source": [
    "# Average speed aa_medium\n",
    "\n",
    "# 1. Main filter\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Overall average\n",
    "avg_speed_aa_medium = filtered['Runtime (s)'].mean()\n",
    "print(f\"Average runtime for dna_easy: {avg_speed_aa_medium:.2f} s\\n\")\n",
    "\n",
    "# 3. Specific epsilon values\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Filter only the desired epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Compute average per epsilon\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Output\n",
    "print(\"Average runtime per epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40c852d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime for dna_easy: 212.10 s\n",
      "\n",
      "Average runtime per epsilon:\n",
      "  Epsilon=0.000100 → 280.44 s\n",
      "  Epsilon=0.000500 → 258.11 s\n",
      "  Epsilon=0.001000 → 214.56 s\n",
      "  Epsilon=0.005000 → 203.56 s\n",
      "  Epsilon=0.010000 → 191.44 s\n",
      "  Epsilon=0.100000 → 183.33 s\n",
      "  Epsilon=0.500000 → 153.22 s\n"
     ]
    }
   ],
   "source": [
    "# Average speed aa_hard\n",
    "\n",
    "# 1. Main filter\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Overall average\n",
    "avg_speed_aa_hard = filtered['Runtime (s)'].mean()\n",
    "print(f\"Average runtime for dna_easy: {avg_speed_aa_hard:.2f} s\\n\")\n",
    "\n",
    "# 3. Specific epsilon values\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Filter only the desired epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Compute average per epsilon\n",
    "avg_by_epsilon = filtered_eps.groupby('Epsilon')['Runtime (s)'].mean()\n",
    "\n",
    "# 6. Output\n",
    "print(\"Average runtime per epsilon:\")\n",
    "for eps, avg in avg_by_epsilon.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d007da3a",
   "metadata": {},
   "source": [
    "Mean Log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2144039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average final log-likelihood for dna_easy: -156811.3702\n",
      "\n",
      "Average final log-likelihood per epsilon:\n",
      "  Epsilon=0.000100 → -156778.1694\n",
      "  Epsilon=0.000500 → -156846.4204\n",
      "  Epsilon=0.001000 → -156762.0451\n",
      "  Epsilon=0.005000 → -156757.3232\n",
      "  Epsilon=0.010000 → -156839.9302\n",
      "  Epsilon=0.100000 → -156833.9995\n",
      "  Epsilon=0.500000 → -156861.7040\n"
     ]
    }
   ],
   "source": [
    "# Average final log-likelihood dna_easy\n",
    "\n",
    "# 1. Main filter\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Overall average of Final_Log-likelihood\n",
    "avg_loglik_dna_easy = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Average final log-likelihood for dna_easy: {avg_loglik_dna_easy:.4f}\\n\")\n",
    "\n",
    "# 3. Define epsilon values\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Filtered data only for these epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Average Final_Log-likelihood per epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Output\n",
    "print(\"Average final log-likelihood per epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df9ff442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche Final-Loglikelihood für dna_easy: -63492.8550\n",
      "\n",
      "Durchschnittliche Final-Loglikelihood je Epsilon:\n",
      "  Epsilon=0.000100 → -63482.5385\n",
      "  Epsilon=0.000500 → -63477.9327\n",
      "  Epsilon=0.001000 → -63474.9843\n",
      "  Epsilon=0.005000 → -63509.3536\n",
      "  Epsilon=0.010000 → -63461.2627\n",
      "  Epsilon=0.100000 → -63522.0247\n",
      "  Epsilon=0.500000 → -63521.8880\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittliche Final-Loglikelihood dna_medium\n",
    "\n",
    "# 1. Hauptfilter\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Gesamtdurchschnitt der Final_Log-likelihood\n",
    "avg_loglik_dna_medium = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Durchschnittliche Final-Loglikelihood für dna_easy: {avg_loglik_dna_medium:.4f}\\n\")\n",
    "\n",
    "# 3. Epsilon-Werte definieren\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Gefilterte Daten nur für diese Epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Durchschnittliche Final_Log-likelihood pro Epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Ausgabe\n",
    "print(\"Durchschnittliche Final-Loglikelihood je Epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "955e8523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average final log-likelihood for dna_easy: -14942.8450\n",
      "\n",
      "Average final log-likelihood per epsilon:\n",
      "  Epsilon=0.000100 → -14932.8311\n",
      "  Epsilon=0.000500 → -14942.4876\n",
      "  Epsilon=0.001000 → -14954.1691\n",
      "  Epsilon=0.005000 → -14933.4424\n",
      "  Epsilon=0.010000 → -14934.2122\n",
      "  Epsilon=0.100000 → -14967.3503\n",
      "  Epsilon=0.500000 → -14935.4220\n"
     ]
    }
   ],
   "source": [
    "# Average final log-likelihood dna_hard\n",
    "\n",
    "# 1. Main filter\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Overall average of Final_Log-likelihood\n",
    "avg_loglik_dna_hard = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Average final log-likelihood for dna_easy: {avg_loglik_dna_hard:.4f}\\n\")\n",
    "\n",
    "# 3. Define epsilon values\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Filtered data only for these epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Average Final_Log-likelihood per epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Output\n",
    "print(\"Average final log-likelihood per epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb27f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average final log-likelihood for dna_easy: -21462.8462\n",
      "\n",
      "Average final log-likelihood per epsilon:\n",
      "  Epsilon=0.000100 → -21460.8044\n",
      "  Epsilon=0.000500 → -21464.7818\n",
      "  Epsilon=0.001000 → -21457.9213\n",
      "  Epsilon=0.005000 → -21465.9598\n",
      "  Epsilon=0.010000 → -21459.0454\n",
      "  Epsilon=0.100000 → -21456.1469\n",
      "  Epsilon=0.500000 → -21475.2639\n"
     ]
    }
   ],
   "source": [
    "# Average final log-likelihood aa_easy\n",
    "\n",
    "# 1. Main filter\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Overall average of Final_Log-likelihood\n",
    "avg_loglik_aa_easy = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Average final log-likelihood for dna_easy: {avg_loglik_aa_easy:.4f}\\n\")\n",
    "\n",
    "# 3. Define epsilon values\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Filtered data only for these epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Average Final_Log-likelihood per epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Output\n",
    "print(\"Average final log-likelihood per epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9926e5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average final log-likelihood for dna_easy: -17796.0500\n",
      "\n",
      "Average final log-likelihood per epsilon:\n",
      "  Epsilon=0.000100 → -17792.7813\n",
      "  Epsilon=0.000500 → -17794.3679\n",
      "  Epsilon=0.001000 → -17793.9185\n",
      "  Epsilon=0.005000 → -17793.2383\n",
      "  Epsilon=0.010000 → -17800.5230\n",
      "  Epsilon=0.100000 → -17792.4883\n",
      "  Epsilon=0.500000 → -17805.0325\n"
     ]
    }
   ],
   "source": [
    "# Average final log-likelihood aa_medium\n",
    "\n",
    "# 1. Main filter\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Overall average of Final_Log-likelihood\n",
    "avg_loglik_aa_medium = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Average final log-likelihood for dna_easy: {avg_loglik_aa_medium:.4f}\\n\")\n",
    "\n",
    "# 3. Define epsilon values\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Filtered data only for these epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Average Final_Log-likelihood per epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Output\n",
    "print(\"Average final log-likelihood per epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64c00187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average final log-likelihood for dna_easy: -5949.1022\n",
      "\n",
      "Average final log-likelihood per epsilon:\n",
      "  Epsilon=0.000100 → -5950.2694\n",
      "  Epsilon=0.000500 → -5951.0615\n",
      "  Epsilon=0.001000 → -5946.4386\n",
      "  Epsilon=0.005000 → -5943.9783\n",
      "  Epsilon=0.010000 → -5950.1080\n",
      "  Epsilon=0.100000 → -5951.7140\n",
      "  Epsilon=0.500000 → -5950.1457\n"
     ]
    }
   ],
   "source": [
    "# Average final log-likelihood aa_hard\n",
    "\n",
    "# 1. Main filter\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Overall average of Final_Log-likelihood\n",
    "avg_loglik_aa_hard = filtered['Final_Log-likelihood'].mean()\n",
    "print(f\"Average final log-likelihood for dna_easy: {avg_loglik_aa_hard:.4f}\\n\")\n",
    "\n",
    "# 3. Define epsilon values\n",
    "eps_values = [0.0001, 0.001, 0.01, 0.1, 0.005, 0.0005, 0.5]\n",
    "\n",
    "# 4. Filtered data only for these epsilons\n",
    "filtered_eps = filtered[filtered['Epsilon'].isin(eps_values)]\n",
    "\n",
    "# 5. Average Final_Log-likelihood per epsilon\n",
    "avg_loglik_by_eps = filtered_eps.groupby('Epsilon')['Final_Log-likelihood'].mean().sort_index()\n",
    "\n",
    "# 6. Output\n",
    "print(\"Average final log-likelihood per epsilon:\")\n",
    "for eps, avg in avg_loglik_by_eps.items():\n",
    "    print(f\"  Epsilon={eps:.6f} → {avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d2a79",
   "metadata": {},
   "source": [
    "Anzahl der Fehlerhaften runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7d8fd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 out of 70 runs were incomplete.\n",
      "\n",
      "Incomplete runs (Dataset + Comment):\n",
      "                                 Dataset                    Comment\n",
      "63            prumd6_L37.processed.fasta       Unfinished .log file\n",
      "118  jarvd5a_intron_1521.processed.fasta  No .logl and _tree.newick\n",
      "119     jarvd5b_bin.1136.processed.fasta  No .logl and _tree.newick\n",
      "120    misod2a_EOG5CVDNS.processed.fasta  No .logl and _tree.newick\n",
      "121    misod2b_EOG5CVDNS.processed.fasta  No .logl and _tree.newick\n",
      "122           prumd6_L37.processed.fasta  No .logl and _tree.newick\n"
     ]
    }
   ],
   "source": [
    "# Failed runs dna_easy (detected via 'comment')\n",
    "\n",
    "# 1. Main filter (as before)\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Total number of runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Incomplete runs = those with a comment (not empty / not NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Number of incomplete runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Output\n",
    "print(f\"{failed_runs} out of {total_runs} runs were incomplete.\\n\")\n",
    "\n",
    "# 6. Output incomplete runs with dataset and comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Incomplete runs (Dataset + Comment):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Columns 'Dataset' or 'Comment' not found – here are all available columns:\")\n",
    "    print(incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eebae50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 70 runs were incomplete.\n",
      "\n",
      "Incomplete runs (Dataset + Comment):\n",
      "Empty DataFrame\n",
      "Columns: [Dataset, Comment]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Failed runs dna_medium (detected via 'comment')\n",
    "\n",
    "# 1. Main filter (as before)\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Total number of runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Incomplete runs = those with a comment (not empty / not NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Number of incomplete runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Output\n",
    "print(f\"{failed_runs} out of {total_runs} runs were incomplete.\\n\")\n",
    "\n",
    "# 6. Output incomplete runs with Dataset and Comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Incomplete runs (Dataset + Comment):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Columns 'Dataset' or 'Comment' not found – here are all available columns:\")\n",
    "    print(incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a99b042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 70 runs were incomplete.\n",
      "\n",
      "Incomplete runs (Dataset + Comment):\n",
      "Empty DataFrame\n",
      "Columns: [Dataset, Comment]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Failed runs dna_hard (detected via 'comment')\n",
    "\n",
    "# 1. Main filter (as before)\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'dna')]\n",
    "\n",
    "# 2. Total number of runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Incomplete runs = those with a comment (not empty / not NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Number of incomplete runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Output\n",
    "print(f\"{failed_runs} out of {total_runs} runs were incomplete.\\n\")\n",
    "\n",
    "# 6. Output incomplete runs with Dataset and Comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Incomplete runs (Dataset + Comment):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Columns 'Dataset' or 'Comment' not found – here are all available columns:\")\n",
    "    print(incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "900772f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 out of 77 runs were incomplete.\n",
      "\n",
      "Incomplete runs (Dataset + Comment):\n",
      "                                    Dataset      Comment\n",
      "31   chena4_Pro_ENSG00000143061.refined.fas  Not started\n",
      "90   chena4_Pro_ENSG00000143061.refined.fas  Not Started\n",
      "149  chena4_Pro_ENSG00000143061.refined.fas  Not Started\n",
      "208  chena4_Pro_ENSG00000143061.refined.fas  Not Started\n",
      "267  chena4_Pro_ENSG00000143061.refined.fas  Not Started\n",
      "326  chena4_Pro_ENSG00000143061.refined.fas  Not Started\n",
      "385  chena4_Pro_ENSG00000143061.refined.fas  Not Started\n"
     ]
    }
   ],
   "source": [
    "# Failed runs aa_easy (detected via 'comment')\n",
    "\n",
    "# 1. Main filter (as before)\n",
    "filtered = df[(df['Difficulty'] == 'easy') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Total number of runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Incomplete runs = those with a comment (not empty / not NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Number of incomplete runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Output\n",
    "print(f\"{failed_runs} out of {total_runs} runs were incomplete.\\n\")\n",
    "\n",
    "# 6. Output incomplete runs with Dataset and Comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Incomplete runs (Dataset + Comment):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Columns 'Dataset' or 'Comment' not found – here are all available columns:\")\n",
    "    print(incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca792f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 out of 63 runs were incomplete.\n",
      "\n",
      "Incomplete runs (Dataset + Comment):\n",
      "                                    Dataset      Comment\n",
      "42   chena4_Pro_ENSG00000156958.refined.fas  Not Started\n",
      "101  chena4_Pro_ENSG00000156958.refined.fas  Not Started\n",
      "160  chena4_Pro_ENSG00000156958.refined.fas  Not Started\n",
      "219  chena4_Pro_ENSG00000156958.refined.fas  Not Started\n",
      "337  chena4_Pro_ENSG00000156958.refined.fas  Not Started\n",
      "396  chena4_Pro_ENSG00000156958.refined.fas  Not Started\n"
     ]
    }
   ],
   "source": [
    "# Failed runs aa_medium (detected via 'comment')\n",
    "\n",
    "# 1. Main filter (as before)\n",
    "filtered = df[(df['Difficulty'] == 'medium') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Total number of runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Incomplete runs = those with a comment (not empty / not NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Number of incomplete runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Output\n",
    "print(f\"{failed_runs} out of {total_runs} runs were incomplete.\\n\")\n",
    "\n",
    "# 6. Output incomplete runs with Dataset and Comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Incomplete runs (Dataset + Comment):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Columns 'Dataset' or 'Comment' not found – here are all available columns:\")\n",
    "    print(incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49629416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 out of 63 runs were incomplete.\n",
      "\n",
      "Incomplete runs (Dataset + Comment):\n",
      "                                    Dataset     Comment\n",
      "51   chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "110  chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "169  chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "228  chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "287  chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "346  chena4_Pro_ENSG00000141543.refined.fas  No Started\n",
      "405  chena4_Pro_ENSG00000141543.refined.fas  No Started\n"
     ]
    }
   ],
   "source": [
    "# Failed runs aa_hard (detected via 'comment')\n",
    "\n",
    "# 1. Main filter (as before)\n",
    "filtered = df[(df['Difficulty'] == 'hard') & (df['Type'] == 'aa')]\n",
    "\n",
    "# 2. Total number of runs\n",
    "total_runs = len(filtered)\n",
    "\n",
    "# 3. Incomplete runs = those with a comment (not empty / not NaN)\n",
    "incomplete = filtered[filtered['Comment'].notna() & (filtered['Comment'].astype(str).str.strip() != '')]\n",
    "\n",
    "# 4. Number of incomplete runs\n",
    "failed_runs = len(incomplete)\n",
    "\n",
    "# 5. Output\n",
    "print(f\"{failed_runs} out of {total_runs} runs were incomplete.\\n\")\n",
    "\n",
    "# 6. Output incomplete runs with Dataset and Comment\n",
    "if 'Dataset' in incomplete.columns and 'Comment' in incomplete.columns:\n",
    "    print(\"Incomplete runs (Dataset + Comment):\")\n",
    "    print(incomplete[['Dataset', 'Comment']])\n",
    "else:\n",
    "    print(\"Columns 'Dataset' or 'Comment' not found – here are all available columns:\")\n",
    "    print(incomplete)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
